{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP7QCt9zQVSYAQjfFGr7g+p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":773},"id":"rVKl9xCtO-Ma","executionInfo":{"status":"error","timestamp":1711535067744,"user_tz":-330,"elapsed":3929,"user":{"displayName":"A G","userId":"11086915054296872235"}},"outputId":"4e047318-b6d8-436a-dca1-1b5e16686df3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"error","ename":"ValueError","evalue":"in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 10, 10) and (None, 10) are incompatible\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-73df7d163a4f>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#Train the model on the training data I\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m# Evalute the model on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 10, 10) and (None, 10) are incompatible\n"]}],"source":["import numpy as np\n","from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from keras.utils import to_categorical\n","#Load CIFAR-10 dataset\n","(x_train, y_train), (x_test, y_test)= cifar10.load_data()\n","#Normalize pixel values to be between 0 and 1\n","x_train = x_train.astype('float32') / 255\n","x_test = x_test.astype('float32') / 255\n","# Convert class labels to one-hot encoded vectors\n","y_train = to_categorical(y_train, num_classes=10)\n","y_test = to_categorical(y_test, num_classes=10)\n","#Create a Sequential model\n","model= Sequential()\n","#Add a Convolutional layer with 32 filters, kernel size 3, and Bat activation function\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n","#Add a RasPooling layer with pool size 2x2\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","#Add another Convolutional layer with 64 filters, kernel size s), and Rell activation function\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","#Add another Rasooling layer with pool size 202\n","model.add(MaxPooling2D(pool_size =(2, 2)))\n","#Flatten the output from the convolutional layers\n","model.add(Flatten())\n","#Add a fully connected layer with 64 neurons and ReLU activation function\n","#   y_train=to_categorical(y_train, num_classes=10)\n","#Add the output layer with 10 neurons (one for each class) and softmax activation function\n","model.add(Dense(10, activation='softmax'))\n","#Compile the model with Adam optimizer, categorical crossentropy loss, and accuracy metric\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","#Train the model on the training data I\n","model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n","# Evalute the model on the test data\n","loss, accuracy = model.evaluate(x_test,y_test);\n","\n","print(f'Test Loss:{loss}')\n","print(f'Test Accuracy :{accuracy}')\n"]},{"cell_type":"code","source":["import numpy as np\n","from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from keras.utils import to_categorical\n","\n","# Load CIFAR-10 dataset\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# Normalize pixel values to be between 0 and 1\n","x_train = x_train.astype('float32') / 255\n","x_test = x_test.astype('float32') / 255\n","\n","# Convert class labels to one-hot encoded vectors\n","y_train = to_categorical(y_train, num_classes=10)\n","y_test = to_categorical(y_test, num_classes=10)\n","\n","# Create a Sequential model\n","model = Sequential()\n","\n","# Add a Convolutional layer with 32 filters, kernel size 3, and ReLU activation function\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n","\n","# Add a MaxPooling layer with pool size 2x2\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Add another Convolutional layer with 64 filters, kernel size 3, and ReLU activation function\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","\n","# Add another MaxPooling layer with pool size 2x2\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Flatten the output from the convolutional layers\n","model.add(Flatten())\n","\n","# Add a fully connected layer with 64 neurons and ReLU activation function\n","model.add(Dense(64, activation='relu'))\n","\n","# Add the output layer with 10 neurons (one for each class) and softmax activation function\n","model.add(Dense(10, activation='softmax'))\n","\n","# Compile the model with Adam optimizer, categorical crossentropy loss, and accuracy metric\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model on the training data\n","model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n","\n","# Evaluate the model on the test data\n","loss, accuracy = model.evaluate(x_test, y_test)\n","\n","print(f'Test Loss: {loss}')\n","print(f'Test Accuracy: {accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NsBSkxduceM5","executionInfo":{"status":"ok","timestamp":1711535851105,"user_tz":-330,"elapsed":691311,"user":{"displayName":"A G","userId":"11086915054296872235"}},"outputId":"895e59c8-94ce-4d62-9abe-bd92d17fd467"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1563/1563 [==============================] - 73s 46ms/step - loss: 1.4722 - accuracy: 0.4675 - val_loss: 1.2454 - val_accuracy: 0.5681\n","Epoch 2/10\n","1563/1563 [==============================] - 66s 42ms/step - loss: 1.1255 - accuracy: 0.6044 - val_loss: 1.1502 - val_accuracy: 0.5953\n","Epoch 3/10\n","1563/1563 [==============================] - 66s 42ms/step - loss: 0.9959 - accuracy: 0.6545 - val_loss: 0.9927 - val_accuracy: 0.6522\n","Epoch 4/10\n","1563/1563 [==============================] - 67s 43ms/step - loss: 0.9112 - accuracy: 0.6830 - val_loss: 0.9794 - val_accuracy: 0.6591\n","Epoch 5/10\n","1563/1563 [==============================] - 67s 43ms/step - loss: 0.8485 - accuracy: 0.7036 - val_loss: 0.9559 - val_accuracy: 0.6696\n","Epoch 6/10\n","1563/1563 [==============================] - 67s 43ms/step - loss: 0.7898 - accuracy: 0.7277 - val_loss: 0.9254 - val_accuracy: 0.6829\n","Epoch 7/10\n","1563/1563 [==============================] - 69s 44ms/step - loss: 0.7399 - accuracy: 0.7433 - val_loss: 0.9265 - val_accuracy: 0.6781\n","Epoch 8/10\n","1563/1563 [==============================] - 73s 47ms/step - loss: 0.6971 - accuracy: 0.7579 - val_loss: 0.9464 - val_accuracy: 0.6779\n","Epoch 9/10\n","1563/1563 [==============================] - 67s 43ms/step - loss: 0.6546 - accuracy: 0.7702 - val_loss: 0.9139 - val_accuracy: 0.6900\n","Epoch 10/10\n","1563/1563 [==============================] - 66s 42ms/step - loss: 0.6141 - accuracy: 0.7841 - val_loss: 0.8955 - val_accuracy: 0.7025\n","313/313 [==============================] - 4s 12ms/step - loss: 0.8955 - accuracy: 0.7025\n","Test Loss: 0.8954525589942932\n","Test Accuracy: 0.7024999856948853\n"]}]}]}